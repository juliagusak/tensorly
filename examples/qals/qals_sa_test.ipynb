{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import peach as p\n",
    "\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.kruskal_tensor import kruskal_to_tensor, KruskalTensor\n",
    "from tensorly.base import unfold\n",
    "\n",
    "from tensorly.decomposition import quantized_parafac\n",
    "from tensorly.quantization import quantize_qint\n",
    "\n",
    "import torch\n",
    "tl.set_backend('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_to_struct = {np.float32 : 'f', np.int8 : 'i'}\n",
    "pytorch_to_struct = {torch.float32 : 'f', torch.int8 : 'i'}\n",
    "\n",
    "N_ITER_MAX = 10000\n",
    "RANDOM_INIT_STARTS = 10\n",
    "\n",
    "\n",
    "params_als_shared = {'n_iter_max' : N_ITER_MAX,\\\n",
    "                    'stop_criterion' : 'rec_error_decrease',\\\n",
    "                    'tol' : None,\\\n",
    "                    'normalize_factors' : True,\\\n",
    "                    'svd' : 'numpy_svd',\\\n",
    "                    'verbose' : 0}\n",
    "\n",
    "params_als = {'orthogonalise' : False,\\\n",
    "              'non_negative' : False,\\\n",
    "              'mask' : None,\\\n",
    "              'return_errors' : False}\n",
    "\n",
    "params_qint = {'dtype' : torch.qint8,\\\n",
    "               'qscheme' : torch.per_channel_affine,\\\n",
    "               'dim' : 1}\n",
    "\n",
    "params_qals = {'qmodes' : [0, 1, 2],\\\n",
    "               'warmup_iters' : 1,\\\n",
    "               'return_scale_zeropoint' : True,\\\n",
    "               'return_rec_errors' : False,\\\n",
    "               'return_qrec_errors' : False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors_init(shape, rank, dtype = 'f'):\n",
    "    if dtype == 'f':\n",
    "        factors = [torch.randn((i, rank)).type(torch.float32)  for i in shape] \n",
    "    elif dtype == 'i':\n",
    "        factors = [torch.randint(-256, 256, (i, rank)).type(torch.int8) for i in shape]\n",
    "        \n",
    "    return factors\n",
    "\n",
    "pytorch_to_struct = {torch.float32 : 'f',\\\n",
    "                     torch.float64 : 'd',\\\n",
    "                     torch.float16 : 'e',\\\n",
    "                     torch.int8 : 'b',\\\n",
    "                     torch.int16 : 'h',\\\n",
    "                     torch.int32 : 'i',\\\n",
    "                     torch.int64 : 'q',\\\n",
    "                     torch.uint8 : 'B',\\\n",
    "                     torch.qint8 : 'b',\\\n",
    "                     torch.quint8 : 'B',\\\n",
    "                     torch.qint32 : 'i'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tensor in Kruskal format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||factors||: 132.60455322265625, factors type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "rank = 9\n",
    "shape = (16, 16, 9)\n",
    "\n",
    "dtype =  torch.float32\n",
    "struct_dtype = pytorch_to_struct[dtype]\n",
    "\n",
    "factors = get_factors_init(shape, rank, dtype = struct_dtype)\n",
    "weights = torch.ones(rank).type(dtype)\n",
    "\n",
    "krt = KruskalTensor((weights, factors))\n",
    "t = kruskal_to_tensor(krt)\n",
    "\n",
    "tnorm = tl.norm(t.type(torch.float32))\n",
    "print('||factors||: {}, factors type: {}'.format(tnorm, t.dtype))                                                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_init_starts = RANDOM_INIT_STARTS\n",
    "inits = ['svd'] + ['random'] * random_init_starts\n",
    "random_states = [None] + [int(torch.randint(high = 11999, size = (1,))) for _ in range(random_init_starts)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 8\n",
    "\n",
    "run_id = 0\n",
    "init = inits[run_id]\n",
    "random_state = random_states[run_id]\n",
    "\n",
    "out_als = parafac(t, rank,\\\n",
    "              init=init,\\\n",
    "              random_state=random_state,\\\n",
    "              **params_als_shared,\\\n",
    "              **params_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||tensor - als_factors||: 21.873809814453125\n"
     ]
    }
   ],
   "source": [
    "t_als = kruskal_to_tensor(out_als) \n",
    "rec_error_als = tl.norm(t - t_als)\n",
    "\n",
    "print('||tensor - als_factors||: {}'.format(rec_error_als))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS + post quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||tensor - als_factors_quantized||: 21.992183685302734\n"
     ]
    }
   ],
   "source": [
    "qfactors_post = []\n",
    "scales_post = []\n",
    "zero_points_post = []\n",
    "\n",
    "for i in range(len(out_als.factors)):\n",
    "    q, s, z = quantize_qint(out_als.factors[i], **params_qint, return_scale_zeropoint = True)\n",
    "    qfactors_post.append(q)\n",
    "    scales_post.append(s)\n",
    "    zero_points_post.append(z)\n",
    "\n",
    "qt_post = kruskal_to_tensor(KruskalTensor((out_als.weights, qfactors_post)))\n",
    "rec_error_qpost = tl.norm(t - qt_post)\n",
    "\n",
    "print('||tensor - als_factors_quantized||: {}'.format(rec_error_qpost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  40.0000,  -82.0000,   -8.0000,  -43.0000,   55.0000,   -5.0000,\n",
       "           -95.0000,  -37.0000],\n",
       "         [ -57.0000,  -66.0000,  -65.0000,   55.0000,  -50.0000,   -3.0000,\n",
       "           -34.0000,   25.0000],\n",
       "         [ -23.0000,  -31.0000,  -97.0000,  -29.0000,  -16.0000,  -20.0000,\n",
       "            30.0000,   14.0000],\n",
       "         [  19.0000,  -12.0000,   13.0000,  -64.0000,  -63.0000,   42.0000,\n",
       "           -58.0000,   27.0000],\n",
       "         [   3.0000,   31.0000,   42.0000,  -22.0000,   42.0000,   45.0000,\n",
       "             3.0000,  -36.0000],\n",
       "         [ -42.0000,  -12.0000,   58.0000,    4.0000,  -54.0000,   26.0000,\n",
       "            47.0000,  -37.0000],\n",
       "         [ -10.0000,  -24.0000,   36.0000,   61.0000,   10.0000,  -17.0000,\n",
       "            45.0000,  -31.0000],\n",
       "         [  87.0000,  -27.0000,  -53.0000,  -89.0000,   43.0000,   79.0000,\n",
       "           -86.0000,   12.0000],\n",
       "         [ -85.0000,   62.0000,  -10.0000,  -50.0000,  -22.0000,   70.0000,\n",
       "           -68.0000,  -26.0000],\n",
       "         [  22.0000,  -16.0000,   -6.0000,  -10.0000,   53.0000,   22.0000,\n",
       "            49.0000,  -67.0000],\n",
       "         [  21.0000,   35.0000,  -13.0000,    4.0000,   28.0000,   79.0000,\n",
       "            14.0000,   18.0000],\n",
       "         [  24.0000,  -15.0000,   18.0000,   24.0000,   49.0000,   -7.0000,\n",
       "            12.0000,  -67.0000],\n",
       "         [  19.0000,   -9.0000,   69.0000,  -66.0000,  -48.0000,  -58.0000,\n",
       "            10.0000,  -56.0000],\n",
       "         [ -62.0000,   -9.0000,   52.0000,  -18.0000,  -10.0000,   65.0000,\n",
       "           -12.0000,    5.0000],\n",
       "         [  12.0000,   20.0000,   18.0000,  -82.0000, -111.0000,    7.0000,\n",
       "           -61.0000,   42.0000],\n",
       "         [  -6.0000,   87.0000,   57.0000,  -26.0000,  -50.0000,   -7.0000,\n",
       "           -70.0000,   85.0000]]),\n",
       " [tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qfactors_post[0]/scales_post[0],  zero_points_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||tensor - qals_factors||: 21.998783111572266\n"
     ]
    }
   ],
   "source": [
    "(fout, qout), (errors, qerrors), scales, zero_points = quantized_parafac(t, rank,\\\n",
    "                                                                         init=init,\\\n",
    "                                                                         random_state=random_state,\\\n",
    "                                                                         **params_als_shared,\\\n",
    "                                                                         **params_qals,\\\n",
    "                                                                         **params_qint)\n",
    "\n",
    "t_approx_qals = kruskal_to_tensor(KruskalTensor(qout))\n",
    "rec_error_qals = tl.norm(t - t_approx_qals)\n",
    "\n",
    "print('||tensor - qals_factors||: {}'.format(rec_error_qals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 40.0000, -81.0000,   7.0000,  80.0000, -45.0000,   5.0000, -43.0000,\n",
       "          -37.0000],\n",
       "         [-57.0000, -66.0000,  58.0000,  29.0000,  41.0000,   4.0000,  55.0000,\n",
       "           25.0000],\n",
       "         [-23.0000, -31.0000,  87.0000, -26.0000,  13.0000,  22.0000, -29.0000,\n",
       "           14.0000],\n",
       "         [ 20.0000, -12.0000, -12.0000,  50.0000,  52.0000, -46.0000, -64.0000,\n",
       "           27.0000],\n",
       "         [  3.0000,  31.0000, -38.0000,  -2.0000, -34.0000, -49.0000, -22.0000,\n",
       "          -36.0000],\n",
       "         [-42.0000, -12.0000, -52.0000, -40.0000,  45.0000, -29.0000,   4.0000,\n",
       "          -37.0000],\n",
       "         [-10.0000, -24.0000, -33.0000, -39.0000,  -8.0000,  19.0000,  61.0000,\n",
       "          -31.0000],\n",
       "         [ 87.0000, -27.0000,  48.0000,  73.0000, -35.0000, -86.0000, -90.0000,\n",
       "           11.0000],\n",
       "         [-85.0000,  62.0000,   9.0000,  58.0000,  18.0000, -76.0000, -49.0000,\n",
       "          -25.0000],\n",
       "         [ 22.0000, -16.0000,   6.0000, -42.0000, -44.0000, -25.0000, -10.0000,\n",
       "          -67.0000],\n",
       "         [ 21.0000,  35.0000,  11.0000, -12.0000, -23.0000, -86.0000,   4.0000,\n",
       "           18.0000],\n",
       "         [ 24.0000, -15.0000, -16.0000, -11.0000, -40.0000,   7.0000,  23.0000,\n",
       "          -67.0000],\n",
       "         [ 19.0000,  -9.0000, -62.0000,  -8.0000,  40.0000,  63.0000, -66.0000,\n",
       "          -56.0000],\n",
       "         [-62.0000,  -9.0000, -47.0000,  11.0000,   8.0000, -70.0000, -18.0000,\n",
       "            5.0000],\n",
       "         [ 12.0000,  20.0000, -16.0000,  52.0000,  91.0000,  -8.0000, -82.0000,\n",
       "           42.0000],\n",
       "         [ -6.0000,  87.0000, -52.0000,  59.0000,  41.0000,   8.0000, -26.0000,\n",
       "           85.0000]]),\n",
       " tensor([59.3764, 58.6129, 43.9713, 35.6382, 44.1792, 44.3945, 34.4950, 37.3455]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qout.factors[0]/scales[0], qout.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_factors(factors_flatten, shapes):\n",
    "    factors_restored = []\n",
    "    l = 0\n",
    "    for shape in shapes:\n",
    "        dl = np.prod(shape)\n",
    "        factors_restored.append(torch.tensor(factors_flatten)[l : l + dl].reshape(shape))\n",
    "        l += dl\n",
    "    return factors_restored\n",
    "\n",
    "def norm_error(factors_flatten, shapes, t, weights = None,\\\n",
    "               scales = None, zero_points = zero_points):\n",
    "    \n",
    "    factors_restored = restore_factors(factors_flatten, shapes)\n",
    "    if scales is not None:\n",
    "        factors_restored = [(factors_restored[i] - zero_points[0])*scales[i] for i in range(len(scales))]\n",
    "        \n",
    "    tensor_restored = kruskal_to_tensor(KruskalTensor((weights, factors_restored)))\n",
    "\n",
    "    tensor_restored.shape\n",
    "\n",
    "    norm_error = tl.norm(tensor_restored - t)\n",
    "    \n",
    "    print('Norm error: {}'.format(norm_error))\n",
    "    \n",
    "    return float(norm_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS + post quantization + simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  40.0000,  -82.0000,   -8.0000,  -43.0000,   55.0000,   -5.0000,\n",
       "           -95.0000,  -37.0000],\n",
       "         [ -57.0000,  -66.0000,  -65.0000,   55.0000,  -50.0000,   -3.0000,\n",
       "           -34.0000,   25.0000],\n",
       "         [ -23.0000,  -31.0000,  -97.0000,  -29.0000,  -16.0000,  -20.0000,\n",
       "            30.0000,   14.0000],\n",
       "         [  19.0000,  -12.0000,   13.0000,  -64.0000,  -63.0000,   42.0000,\n",
       "           -58.0000,   27.0000],\n",
       "         [   3.0000,   31.0000,   42.0000,  -22.0000,   42.0000,   45.0000,\n",
       "             3.0000,  -36.0000],\n",
       "         [ -42.0000,  -12.0000,   58.0000,    4.0000,  -54.0000,   26.0000,\n",
       "            47.0000,  -37.0000],\n",
       "         [ -10.0000,  -24.0000,   36.0000,   61.0000,   10.0000,  -17.0000,\n",
       "            45.0000,  -31.0000],\n",
       "         [  87.0000,  -27.0000,  -53.0000,  -89.0000,   43.0000,   79.0000,\n",
       "           -86.0000,   12.0000],\n",
       "         [ -85.0000,   62.0000,  -10.0000,  -50.0000,  -22.0000,   70.0000,\n",
       "           -68.0000,  -26.0000],\n",
       "         [  22.0000,  -16.0000,   -6.0000,  -10.0000,   53.0000,   22.0000,\n",
       "            49.0000,  -67.0000],\n",
       "         [  21.0000,   35.0000,  -13.0000,    4.0000,   28.0000,   79.0000,\n",
       "            14.0000,   18.0000],\n",
       "         [  24.0000,  -15.0000,   18.0000,   24.0000,   49.0000,   -7.0000,\n",
       "            12.0000,  -67.0000],\n",
       "         [  19.0000,   -9.0000,   69.0000,  -66.0000,  -48.0000,  -58.0000,\n",
       "            10.0000,  -56.0000],\n",
       "         [ -62.0000,   -9.0000,   52.0000,  -18.0000,  -10.0000,   65.0000,\n",
       "           -12.0000,    5.0000],\n",
       "         [  12.0000,   20.0000,   18.0000,  -82.0000, -111.0000,    7.0000,\n",
       "           -61.0000,   42.0000],\n",
       "         [  -6.0000,   87.0000,   57.0000,  -26.0000,  -50.0000,   -7.0000,\n",
       "           -70.0000,   85.0000]]),\n",
       " [tensor([0.0059, 0.0060, 0.0054, 0.0052, 0.0050, 0.0057, 0.0049, 0.0059]),\n",
       "  tensor([0.0052, 0.0061, 0.0058, 0.0051, 0.0051, 0.0064, 0.0050, 0.0059]),\n",
       "  tensor([0.0063, 0.0061, 0.0067, 0.0055, 0.0061, 0.0053, 0.0056, 0.0065])],\n",
       " (tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32)),\n",
       " tensor([59.3663, 58.5466, 43.9686, 34.3537, 44.2857, 44.2403, 35.6504, 37.3341]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qfactors_post[0]/scales_post[0], scales_post, zero_points, out_als.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 22.53983497619629\n"
     ]
    }
   ],
   "source": [
    "qfactors_post_int = [qfactors_post[i]/scales_post[i]\\\n",
    "                     for i in range(len(qfactors_post))]\n",
    "\n",
    "shapes = [factor.shape for factor in qfactors_post_int]\n",
    "factors_flatten_init =  torch.cat([factor.flatten() for factor in qfactors_post_int])\n",
    "factors_flatten_init = factors_flatten_init.type(torch.int8)\n",
    "\n",
    "\n",
    "bsa = None\n",
    "\n",
    "# numpy_to_struct = {np.float32 : 'f', np.float64 : 'd',  np.float16 : 'e',\\\n",
    "#                    np.int8 : 'b', np.int16 : 'h', np.int32 : 'i', np.int64 : 'q',\\\n",
    "#                    np.uint8 : 'B', np.uint16 : 'H', np.uint32 : 'I', np.uint64 : 'Q'}\n",
    "\n",
    "\n",
    "mask = np.zeros(8).astype(bool)\n",
    "mask[-2:] = True\n",
    "\n",
    "neighbor_params = {'nb':2, 'mask': mask}\n",
    "neighbor = p.sa.MaskedBitsNeighbor(**neighbor_params)\n",
    "\n",
    "bsa_als = p.BinarySA(partial(norm_error,\\\n",
    "                         shapes = shapes, t = t, weights = out_als.weights,\\\n",
    "                         scales = scales_post, zero_points = zero_points_post),\\\n",
    "                 np.array(factors_flatten_init).astype(np.int8),\\\n",
    "#                  np.array(flatten_factors_opt),\\\n",
    "                 [(-2**7, 2**7)]*len(factors_flatten_init),\\\n",
    "                 'i'*len(factors_flatten_init),\\\n",
    "                  emax = 1e-10,\\\n",
    "                  imax = 10000,\\\n",
    "                  T0 = 1,\\\n",
    "                  rt = 0.8, neighbor = neighbor)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make sense to run several times\n",
    "for _ in range(100):\n",
    "    flatten_factors_opt_als, error_als =  bsa_als()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 21.998380661010742\n",
      "Norm error: 28.177337646484375\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 33.068416595458984\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 31.785926818847656\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 59.587337493896484\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 42.09645080566406\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 55.714454650878906\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.018604278564453\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 25.422475814819336\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.011640548706055\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 38.034881591796875\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 58.88566589355469\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 25.42574691772461\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 45.86314010620117\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 24.92977523803711\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 45.96036911010742\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 44.70004653930664\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 25.257108688354492\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 23.686552047729492\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 25.462894439697266\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 31.6478214263916\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 40.93667984008789\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 54.901092529296875\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 70.02897644042969\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.00324249267578\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.74641227722168\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 29.664730072021484\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 51.96880340576172\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.000965118408203\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 25.89867401123047\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 34.03062057495117\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 30.948562622070312\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 26.500354766845703\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 26.324111938476562\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 42.78848648071289\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 38.67597961425781\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 41.5859260559082\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 26.376596450805664\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 41.919071197509766\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 36.11152648925781\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 31.699207305908203\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 56.472511291503906\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 31.8469295501709\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 32.82188415527344\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 34.76451110839844\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 36.42887496948242\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 48.92586898803711\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.11214828491211\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.03169822692871\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.1946964263916\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 35.793724060058594\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.008066177368164\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 33.76627731323242\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 34.758331298828125\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 23.598255157470703\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 42.837703704833984\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 46.52725601196289\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 27.639711380004883\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.001113891601562\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 34.67212677001953\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 23.282808303833008\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 40.36046600341797\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 38.60722351074219\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 39.37659454345703\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 34.0626335144043\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 45.27376937866211\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 39.20918655395508\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 34.82463455200195\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.277528762817383\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 23.376079559326172\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.0050106048584\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 24.663116455078125\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 26.17420196533203\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 23.74834632873535\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 31.11968994140625\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.011070251464844\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.475278854370117\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 39.762821197509766\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 24.478578567504883\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 32.012184143066406\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 69.44615173339844\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 35.763023376464844\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 66.47689819335938\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 56.89628219604492\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 42.417991638183594\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 35.3065185546875\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.00400733947754\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 39.58241653442383\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.025362014770508\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.4009952545166\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 44.28016662597656\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 37.28163146972656\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 30.80217170715332\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.652408599853516\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 37.223487854003906\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 35.401336669921875\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 22.280134201049805\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 32.87474822998047\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 28.502429962158203\n",
      "Norm error: 21.998380661010742\n",
      "Norm error: 21.998380661010742\n"
     ]
    }
   ],
   "source": [
    "flatten_factors_opt_als, error_als =  bsa_als()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QALS + simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 40.0000, -81.0000,   7.0000,  80.0000, -45.0000,   5.0000, -43.0000,\n",
       "          -37.0000],\n",
       "         [-57.0000, -66.0000,  58.0000,  29.0000,  41.0000,   4.0000,  55.0000,\n",
       "           25.0000],\n",
       "         [-23.0000, -31.0000,  87.0000, -26.0000,  13.0000,  22.0000, -29.0000,\n",
       "           14.0000],\n",
       "         [ 20.0000, -12.0000, -12.0000,  50.0000,  52.0000, -46.0000, -64.0000,\n",
       "           27.0000],\n",
       "         [  3.0000,  31.0000, -38.0000,  -2.0000, -34.0000, -49.0000, -22.0000,\n",
       "          -36.0000],\n",
       "         [-42.0000, -12.0000, -52.0000, -40.0000,  45.0000, -29.0000,   4.0000,\n",
       "          -37.0000],\n",
       "         [-10.0000, -24.0000, -33.0000, -39.0000,  -8.0000,  19.0000,  61.0000,\n",
       "          -31.0000],\n",
       "         [ 87.0000, -27.0000,  48.0000,  73.0000, -35.0000, -86.0000, -90.0000,\n",
       "           11.0000],\n",
       "         [-85.0000,  62.0000,   9.0000,  58.0000,  18.0000, -76.0000, -49.0000,\n",
       "          -25.0000],\n",
       "         [ 22.0000, -16.0000,   6.0000, -42.0000, -44.0000, -25.0000, -10.0000,\n",
       "          -67.0000],\n",
       "         [ 21.0000,  35.0000,  11.0000, -12.0000, -23.0000, -86.0000,   4.0000,\n",
       "           18.0000],\n",
       "         [ 24.0000, -15.0000, -16.0000, -11.0000, -40.0000,   7.0000,  23.0000,\n",
       "          -67.0000],\n",
       "         [ 19.0000,  -9.0000, -62.0000,  -8.0000,  40.0000,  63.0000, -66.0000,\n",
       "          -56.0000],\n",
       "         [-62.0000,  -9.0000, -47.0000,  11.0000,   8.0000, -70.0000, -18.0000,\n",
       "            5.0000],\n",
       "         [ 12.0000,  20.0000, -16.0000,  52.0000,  91.0000,  -8.0000, -82.0000,\n",
       "           42.0000],\n",
       "         [ -6.0000,  87.0000, -52.0000,  59.0000,  41.0000,   8.0000, -26.0000,\n",
       "           85.0000]]),\n",
       " (tensor([0.0059, 0.0060, 0.0060, 0.0057, 0.0061, 0.0052, 0.0052, 0.0059]),\n",
       "  tensor([0.0052, 0.0061, 0.0051, 0.0055, 0.0059, 0.0054, 0.0051, 0.0058]),\n",
       "  tensor([0.0063, 0.0061, 0.0067, 0.0056, 0.0061, 0.0053, 0.0055, 0.0049])),\n",
       " (tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.int32)),\n",
       " tensor([59.3764, 58.6129, 43.9713, 35.6382, 44.1792, 44.3945, 34.4950, 37.3455]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qout.factors[0]/scales[0], scales, zero_points, qout.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 22.58852767944336\n"
     ]
    }
   ],
   "source": [
    "qout_factors_int = [qout.factors[i]/scales[i] for i in range(len(qout.factors))]\n",
    "\n",
    "shapes = [factor.shape for factor in qout_factors_int]\n",
    "factors_flatten_init =  torch.cat([factor.flatten() for factor in qout_factors_int])\n",
    "factors_flatten_init = factors_flatten_init.type(torch.int8)\n",
    "\n",
    "\n",
    "bsa = None\n",
    "\n",
    "# numpy_to_struct = {np.float32 : 'f', np.float64 : 'd',  np.float16 : 'e',\\\n",
    "#                    np.int8 : 'b', np.int16 : 'h', np.int32 : 'i', np.int64 : 'q',\\\n",
    "#                    np.uint8 : 'B', np.uint16 : 'H', np.uint32 : 'I', np.uint64 : 'Q'}\n",
    "\n",
    "\n",
    "mask = np.zeros(8).astype(bool)\n",
    "mask[-2:] = True\n",
    "\n",
    "neighbor_params = {'nb':2, 'mask': mask}\n",
    "neighbor = p.sa.MaskedBitsNeighbor(**neighbor_params)\n",
    "\n",
    "bsa_qals = p.BinarySA(partial(norm_error,\\\n",
    "                         shapes = shapes, t = t, weights = qout.weights,\\\n",
    "                         scales = scales, zero_points = zero_points),\\\n",
    "                 np.array(factors_flatten_init).astype(np.int8),\\\n",
    "#                  np.array(flatten_factors_opt),\\\n",
    "                 [(-2**7, 2**7)]*len(factors_flatten_init),\\\n",
    "                 'i'*len(factors_flatten_init),\\\n",
    "                  emax = 1e-10,\\\n",
    "                  imax = 10000,\\\n",
    "                  T0 = 1,\\\n",
    "                  rt = 0.8, neighbor = neighbor)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make sense to run several times\n",
    "for j in range(100):\n",
    "    print('=========================={}=========================='.format(j))\n",
    "    flatten_factors_opt_qals, error_qals =  bsa_qals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.105695724487305\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.949188232421875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 60.16566467285156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.516637802124023\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 49.08021545410156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.264850616455078\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.79775619506836\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 53.3630485534668\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.091899871826172\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.758569717407227\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.20972442626953\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.25651168823242\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.05971145629883\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 51.181209564208984\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.776613235473633\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.031818389892578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 42.89373016357422\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.954919815063477\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.337602615356445\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.3424015045166\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.58674430847168\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.053409576416016\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.643184661865234\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03561782836914\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.389909744262695\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.036605834960938\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.596832275390625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 50.59867477416992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.491214752197266\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.87765121459961\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.211585998535156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.143768310546875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 48.362491607666016\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.75771713256836\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.78154754638672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.228965759277344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.11237335205078\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.44426727294922\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.682395935058594\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 58.05156326293945\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.91771697998047\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.406150817871094\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.87218475341797\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.55156707763672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.524412155151367\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.907867431640625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.031208038330078\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.18307113647461\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.178281784057617\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.878236770629883\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.041746139526367\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.38106918334961\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.328872680664062\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03360366821289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.810623168945312\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.285037994384766\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.038301467895508\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.175155639648438\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03398323059082\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.855146408081055\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.14997100830078\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.3116512298584\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.402902603149414\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.56047821044922\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.039188385009766\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 44.387752532958984\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 47.54445266723633\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.714815139770508\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.26069259643555\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.70901870727539\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.488306045532227\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.21249008178711\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 89.31939697265625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 57.555416107177734\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.802120208740234\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.317916870117188\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.821901321411133\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.04558563232422\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.55337905883789\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.69549560546875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.34113311767578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.18106460571289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.216184616088867\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 47.154823303222656\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.045385360717773\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.56843185424805\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.035375595092773\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 70.32344818115234\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 41.464630126953125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.02787399291992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.030427932739258\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.87107467651367\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.48056411743164\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.24432373046875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.052139282226562\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.767229080200195\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.100446701049805\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.7903938293457\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.01192855834961\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.827054977416992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.770923614501953\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.83450698852539\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.383358001708984\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.045900344848633\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.92357635498047\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.27543640136719\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.110502243041992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.19451904296875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.39141845703125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.534461975097656\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.091838836669922\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 65.52629852294922\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.01445388793945\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.02939796447754\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.7020149230957\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.470609664916992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.04801368713379\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 46.254371643066406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.345149993896484\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.78687286376953\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03034019470215\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.025781631469727\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.135894775390625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.00288200378418\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 48.45762252807617\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.035430908203125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.42606735229492\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.185136795043945\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.3297119140625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.962522506713867\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 66.58341217041016\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.964624404907227\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.831886291503906\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.184446334838867\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.1470890045166\n",
      "Norm error: 22.027708053588867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 35.830814361572266\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 47.307003021240234\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.188682556152344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.57244300842285\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.427173614501953\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.51369857788086\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.51897621154785\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.968097686767578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.19017791748047\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.398393630981445\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 58.95134735107422\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.40958023071289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.41197204589844\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.89562225341797\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 54.54009246826172\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.408166885375977\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.301563262939453\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 55.00235366821289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 42.089942932128906\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.3222770690918\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.567970275878906\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.746803283691406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 48.77225875854492\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.28934097290039\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.91800880432129\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.111326217651367\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.757354736328125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.865489959716797\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.2005500793457\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.873746871948242\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 51.36281204223633\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.72757339477539\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 46.93798828125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.0745792388916\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 41.88154220581055\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03244972229004\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.822002410888672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.16692352294922\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 42.93110275268555\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.642053604125977\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.036027908325195\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.546987533569336\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.726295471191406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.028554916381836\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.517005920410156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.4726448059082\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.90541648864746\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.291929244995117\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 57.83615493774414\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.49201202392578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.461170196533203\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.659420013427734\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 53.07877731323242\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.310752868652344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 51.49646759033203\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 61.482662200927734\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 57.07309341430664\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.548776626586914\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.129173278808594\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.243614196777344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.810382843017578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.141395568847656\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 41.175045013427734\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.067440032958984\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.22402000427246\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.04176139831543\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.386445999145508\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.140600204467773\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.9609317779541\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.573942184448242\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.0151309967041\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.030075073242188\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.554887771606445\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.164310455322266\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 49.22362518310547\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 57.99014663696289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.754697799682617\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.60005760192871\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.746150970458984\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 58.13511276245117\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.91472625732422\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.921886444091797\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.44271469116211\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.28639793395996\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.297876358032227\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.02681541442871\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.645965576171875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.58747863769531\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 47.5009651184082\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.099735260009766\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 57.57661819458008\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.688785552978516\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.704692840576172\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.10914993286133\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 44.656578063964844\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.460811614990234\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.295902252197266\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.071657180786133\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.632526397705078\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.039941787719727\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.11441421508789\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.082500457763672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03260612487793\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 41.115257263183594\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.842952728271484\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.69422149658203\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.0488395690918\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.268314361572266\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 71.83500671386719\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.42417335510254\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.1096305847168\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.88595962524414\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.30082702636719\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.747459411621094\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.931671142578125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.885406494140625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 48.60252380371094\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.412633895874023\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.399322509765625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.541799545288086\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.36829376220703\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.223581314086914\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.36319351196289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.05996322631836\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.212276458740234\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.9549446105957\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.048480987548828\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 72.57777404785156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 53.117008209228516\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.692272186279297\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.052457809448242\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.40655517578125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.3757381439209\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.71998977661133\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03073501586914\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.714801788330078\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.061975479125977\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.781959533691406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.262744903564453\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.46079444885254\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.432924270629883\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.035648345947266\n",
      "Norm error: 22.027708053588867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 48.93480682373047\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.39876365661621\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.10333251953125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.83453369140625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.223302841186523\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.095808029174805\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 65.22598266601562\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.28342819213867\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.77098846435547\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.18872833251953\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.968456268310547\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.34998321533203\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.988487243652344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.64154052734375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.967384338378906\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.167381286621094\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.37538146972656\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.08619689941406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.36092185974121\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.132171630859375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.048858642578125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.11049461364746\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.705974578857422\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.570070266723633\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.75647735595703\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.755596160888672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.932029724121094\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 47.55995559692383\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.5197639465332\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.06734085083008\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.037702560424805\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.461639404296875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 55.56705856323242\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.252391815185547\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.652565002441406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.39954376220703\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03192901611328\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.340925216674805\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.10776138305664\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.272764205932617\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03318214416504\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.67317199707031\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.862491607666016\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 67.34258270263672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.8448486328125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.233360290527344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 49.74922180175781\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.73617172241211\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.745140075683594\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.034128189086914\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.07730484008789\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.677629470825195\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 61.9985466003418\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 53.27485275268555\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.98407745361328\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 48.94951629638672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.9356803894043\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.041147232055664\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.068443298339844\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.467220306396484\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.86713218688965\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 69.0232925415039\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.787023544311523\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.158119201660156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.7771110534668\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.08805847167969\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.27376365661621\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.907960891723633\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.00080680847168\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.38238525390625\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.9827880859375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.745203018188477\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.342220306396484\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.905359268188477\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.843013763427734\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.71791076660156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.434507369995117\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 49.246307373046875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.296417236328125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.526330947875977\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.716270446777344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.554086685180664\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.8426456451416\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.983861923217773\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03328514099121\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.028949737548828\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 48.36637496948242\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.728618621826172\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.73566436767578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 44.68233108520508\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.20634078979492\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.61720848083496\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.20505714416504\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.133575439453125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.1766242980957\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 80.0129165649414\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.635515213012695\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.439983367919922\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03356170654297\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.96331787109375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.68585968017578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.039575576782227\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 42.71432876586914\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.6076602935791\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.307456970214844\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.31147003173828\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.710052490234375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 51.39345932006836\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.80712127685547\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.234561920166016\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 32.92911148071289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 50.544246673583984\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.483448028564453\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.920818328857422\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.765071868896484\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 58.563602447509766\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.58119010925293\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 33.703468322753906\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 36.66908264160156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.66599655151367\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.77242660522461\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.13370132446289\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.710384368896484\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.043926239013672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.908571243286133\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.74808120727539\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.034936904907227\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.078933715820312\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.46195602416992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.27423858642578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.129642486572266\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.680814743041992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.07659339904785\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 61.072086334228516\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.287025451660156\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.035491943359375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.03754425048828\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.43637466430664\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.32630729675293\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 51.87508010864258\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 25.318424224853516\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 51.29814147949219\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.924930572509766\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.934093475341797\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 37.088871002197266\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.197208404541016\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.340377807617188\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.22706604003906\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.926986694335938\n",
      "Norm error: 22.027708053588867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 29.109256744384766\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 43.51509475708008\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.271217346191406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 48.570152282714844\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.563446044921875\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.36761474609375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.49357223510742\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.691497802734375\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 28.940778732299805\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.88970184326172\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 51.927467346191406\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 31.295146942138672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.286218643188477\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 24.338239669799805\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.52605056762695\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.97270202636719\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.136817932128906\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.90224838256836\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.15007400512695\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.910783767700195\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 34.547672271728516\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.53920364379883\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.413047790527344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.462390899658203\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 35.28447341918945\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.37821578979492\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.326412200927734\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 23.012845993041992\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 39.28942108154297\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 38.72429656982422\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.24403953552246\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 45.20854568481445\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.073322296142578\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.786161422729492\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 26.831329345703125\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.100862503051758\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 40.647422790527344\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.883296966552734\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.034345626831055\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 27.339881896972656\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 30.39730453491211\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 29.24248504638672\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.753225326538086\n",
      "Norm error: 22.027708053588867\n",
      "Norm error: 22.027708053588867\n"
     ]
    }
   ],
   "source": [
    "flatten_factors_opt_qals, error_qals =  bsa_qals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,\n",
       " -83,\n",
       " 5,\n",
       " 80,\n",
       " -45,\n",
       " 4,\n",
       " -44,\n",
       " -38,\n",
       " -59,\n",
       " -66,\n",
       " 57,\n",
       " 28,\n",
       " 40,\n",
       " 4,\n",
       " 56,\n",
       " 24,\n",
       " -24,\n",
       " -32,\n",
       " 85,\n",
       " -27,\n",
       " 13,\n",
       " 20,\n",
       " -31,\n",
       " 13,\n",
       " 20,\n",
       " -13,\n",
       " -12,\n",
       " 48,\n",
       " 51,\n",
       " -46,\n",
       " -66,\n",
       " 26,\n",
       " 2,\n",
       " 30,\n",
       " -38,\n",
       " -3,\n",
       " -35,\n",
       " -49,\n",
       " -23,\n",
       " -36,\n",
       " -42,\n",
       " -12,\n",
       " -52,\n",
       " -40,\n",
       " 44,\n",
       " -31,\n",
       " 4,\n",
       " -38,\n",
       " -10,\n",
       " -24,\n",
       " -33,\n",
       " -39,\n",
       " -8,\n",
       " 17,\n",
       " 61,\n",
       " -32,\n",
       " 87,\n",
       " -28,\n",
       " 46,\n",
       " 72,\n",
       " -36,\n",
       " -85,\n",
       " -91,\n",
       " 11,\n",
       " -88,\n",
       " 62,\n",
       " 8,\n",
       " 57,\n",
       " 16,\n",
       " -76,\n",
       " -52,\n",
       " -27,\n",
       " 22,\n",
       " -16,\n",
       " 5,\n",
       " -42,\n",
       " -43,\n",
       " -26,\n",
       " -12,\n",
       " -68,\n",
       " 21,\n",
       " 33,\n",
       " 10,\n",
       " -12,\n",
       " -24,\n",
       " -86,\n",
       " 4,\n",
       " 18,\n",
       " 24,\n",
       " -16,\n",
       " -16,\n",
       " -11,\n",
       " -40,\n",
       " 5,\n",
       " 23,\n",
       " -68,\n",
       " 19,\n",
       " -11,\n",
       " -61,\n",
       " -9,\n",
       " 40,\n",
       " 61,\n",
       " -69,\n",
       " -58,\n",
       " -63,\n",
       " -10,\n",
       " -47,\n",
       " 9,\n",
       " 8,\n",
       " -71,\n",
       " -19,\n",
       " 4,\n",
       " 11,\n",
       " 20,\n",
       " -16,\n",
       " 52,\n",
       " 89,\n",
       " -8,\n",
       " -84,\n",
       " 41,\n",
       " -7,\n",
       " 86,\n",
       " -52,\n",
       " 58,\n",
       " 40,\n",
       " 8,\n",
       " -28,\n",
       " 85,\n",
       " 53,\n",
       " 45,\n",
       " 35,\n",
       " 60,\n",
       " 64,\n",
       " -4,\n",
       " 12,\n",
       " -5,\n",
       " -53,\n",
       " 66,\n",
       " 47,\n",
       " 9,\n",
       " -48,\n",
       " 13,\n",
       " -39,\n",
       " 12,\n",
       " 52,\n",
       " -5,\n",
       " 58,\n",
       " 70,\n",
       " 25,\n",
       " 44,\n",
       " -29,\n",
       " -52,\n",
       " 0,\n",
       " -6,\n",
       " 48,\n",
       " -48,\n",
       " 11,\n",
       " -31,\n",
       " 36,\n",
       " -44,\n",
       " 24,\n",
       " -10,\n",
       " -92,\n",
       " 52,\n",
       " 80,\n",
       " 17,\n",
       " -16,\n",
       " -88,\n",
       " -1,\n",
       " -35,\n",
       " 44,\n",
       " 72,\n",
       " -24,\n",
       " -33,\n",
       " 22,\n",
       " 32,\n",
       " -104,\n",
       " -56,\n",
       " 16,\n",
       " 27,\n",
       " -25,\n",
       " 68,\n",
       " -13,\n",
       " 4,\n",
       " 8,\n",
       " 92,\n",
       " 44,\n",
       " -8,\n",
       " 85,\n",
       " -24,\n",
       " -75,\n",
       " 29,\n",
       " 64,\n",
       " -15,\n",
       " -71,\n",
       " 22,\n",
       " 16,\n",
       " 44,\n",
       " -33,\n",
       " 82,\n",
       " 4,\n",
       " -19,\n",
       " 44,\n",
       " 32,\n",
       " -46,\n",
       " 12,\n",
       " 16,\n",
       " 25,\n",
       " -46,\n",
       " 34,\n",
       " -52,\n",
       " -35,\n",
       " 15,\n",
       " 57,\n",
       " 23,\n",
       " -13,\n",
       " 33,\n",
       " 22,\n",
       " 27,\n",
       " 70,\n",
       " -9,\n",
       " -120,\n",
       " -42,\n",
       " -62,\n",
       " -53,\n",
       " -2,\n",
       " -6,\n",
       " -52,\n",
       " 13,\n",
       " 53,\n",
       " -17,\n",
       " 39,\n",
       " 41,\n",
       " -36,\n",
       " 61,\n",
       " -39,\n",
       " 25,\n",
       " -36,\n",
       " -128,\n",
       " 53,\n",
       " -67,\n",
       " -21,\n",
       " -42,\n",
       " -18,\n",
       " -54,\n",
       " -12,\n",
       " -29,\n",
       " -12,\n",
       " -8,\n",
       " -60,\n",
       " -20,\n",
       " -27,\n",
       " 14,\n",
       " 37,\n",
       " 56,\n",
       " -19,\n",
       " 5,\n",
       " 89,\n",
       " -18,\n",
       " -43,\n",
       " 91,\n",
       " 35,\n",
       " -74,\n",
       " -10,\n",
       " 95,\n",
       " 84,\n",
       " 4,\n",
       " -91,\n",
       " -64,\n",
       " -116,\n",
       " 51,\n",
       " -128,\n",
       " -56,\n",
       " 14,\n",
       " -46,\n",
       " 76,\n",
       " -16,\n",
       " 52,\n",
       " -104,\n",
       " 40,\n",
       " 49,\n",
       " -11,\n",
       " 15,\n",
       " 61,\n",
       " -31,\n",
       " 26,\n",
       " 25,\n",
       " -87,\n",
       " -8,\n",
       " -10,\n",
       " -46,\n",
       " -19,\n",
       " 57,\n",
       " -74,\n",
       " 74,\n",
       " 12,\n",
       " 30,\n",
       " -56,\n",
       " -41,\n",
       " 64,\n",
       " -36,\n",
       " 66,\n",
       " 59,\n",
       " -55,\n",
       " -24,\n",
       " -48,\n",
       " 106,\n",
       " 30,\n",
       " 42,\n",
       " 1,\n",
       " -72,\n",
       " -95,\n",
       " -72,\n",
       " -32,\n",
       " 55,\n",
       " -82,\n",
       " 79,\n",
       " 57,\n",
       " 28,\n",
       " 48,\n",
       " 57,\n",
       " -72,\n",
       " -44,\n",
       " -32,\n",
       " -8,\n",
       " -67,\n",
       " 24,\n",
       " 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_factors_opt_qals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
