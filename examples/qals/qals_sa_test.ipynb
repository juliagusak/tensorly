{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import peach as p\n",
    "\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.kruskal_tensor import kruskal_to_tensor, KruskalTensor\n",
    "from tensorly.base import unfold\n",
    "\n",
    "from tensorly.decomposition import quantized_parafac\n",
    "from tensorly.quantization import quantize_qint\n",
    "\n",
    "import torch\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_to_struct = {np.float32 : 'f', np.int8 : 'i'}\n",
    "pytorch_to_struct = {torch.float32 : 'f', torch.int8 : 'i'}\n",
    "\n",
    "N_ITER_MAX = 10000\n",
    "RANDOM_INIT_STARTS = 10\n",
    "\n",
    "\n",
    "params_als_shared = {'n_iter_max' : N_ITER_MAX,\\\n",
    "                    'tol' : 1e-18,\\\n",
    "                    'normalize_factors' : True,\\\n",
    "                    'svd' : 'numpy_svd',\\\n",
    "                    'verbose' : 0}\n",
    "\n",
    "params_als = {'orthogonalise' : False,\\\n",
    "              'non_negative' : False,\\\n",
    "              'mask' : None,\\\n",
    "              'return_errors' : False,\\\n",
    "              'stop_criterion' : 'rec_error_deviation'}\n",
    "\n",
    "params_qint = {'dtype' : torch.qint8,\\\n",
    "               'qscheme' : torch.per_channel_affine,\\\n",
    "               'dim' : 1}\n",
    "\n",
    "params_qals = {'qmodes' : [0, 1, 2],\\\n",
    "               'warmup_iters' : 1,\\\n",
    "               'return_scale_zeropoint' : True,\\\n",
    "               'return_rec_errors' : False,\\\n",
    "               'return_qrec_errors' : False,\\\n",
    "               'stop_criterion' : 'both_error_deviation'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors_init(shape, rank, dtype = 'f'):\n",
    "    if dtype == 'f':\n",
    "        factors = [torch.randn((i, rank)).type(torch.float32)  for i in shape] \n",
    "    elif dtype == 'i':\n",
    "        factors = [torch.randint(-256, 256, (i, rank)).type(torch.int8) for i in shape]\n",
    "        \n",
    "    return factors\n",
    "\n",
    "pytorch_to_struct = {torch.float32 : 'f',\\\n",
    "                     torch.float64 : 'd',\\\n",
    "                     torch.float16 : 'e',\\\n",
    "                     torch.int8 : 'b',\\\n",
    "                     torch.int16 : 'h',\\\n",
    "                     torch.int32 : 'i',\\\n",
    "                     torch.int64 : 'q',\\\n",
    "                     torch.uint8 : 'B',\\\n",
    "                     torch.qint8 : 'b',\\\n",
    "                     torch.quint8 : 'B',\\\n",
    "                     torch.qint32 : 'i'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tensor in Kruskal format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||factors||: 154.82830810546875, factors type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "rank = 10\n",
    "shape = (16, 16, 9)\n",
    "\n",
    "rank_expansion = 1\n",
    "\n",
    "dtype =  torch.float32\n",
    "struct_dtype = pytorch_to_struct[dtype]\n",
    "\n",
    "factors = get_factors_init(shape, rank, dtype = struct_dtype)\n",
    "\n",
    "for i in range(len(factors)):\n",
    "    factors[i] = factors[i].repeat(1, rank_expansion)\n",
    "\n",
    "weights = torch.ones(rank * rank_expansion).type(dtype)\n",
    "    \n",
    "\n",
    "krt = KruskalTensor((weights, factors))\n",
    "t = kruskal_to_tensor(krt)\n",
    "\n",
    "tnorm = tl.norm(t.type(torch.float32))\n",
    "print('||factors||: {}, factors type: {}'.format(tnorm, t.dtype))                                                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_init_starts = RANDOM_INIT_STARTS\n",
    "inits = ['svd'] + ['random'] * random_init_starts\n",
    "random_states = [None] + [int(torch.randint(high = 11999, size = (1,))) for _ in range(random_init_starts)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank = rank \n",
    "\n",
    "run_id = 1\n",
    "init = inits[run_id]\n",
    "random_state = random_states[run_id]\n",
    "\n",
    "out_als = None\n",
    "out_als = parafac(t, rank,\\\n",
    "              init=init,\\\n",
    "              random_state=random_state,\\\n",
    "              **params_als_shared,\\\n",
    "              **params_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||tensor - als_factors||: 0.00046896134153939784\n"
     ]
    }
   ],
   "source": [
    "t_als = kruskal_to_tensor(out_als) \n",
    "rec_error_als = tl.norm(t - t_als)\n",
    "\n",
    "print('||tensor - als_factors||: {}'.format(rec_error_als))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([46.4955, 22.5025, 18.7776, 73.8671, 23.2815, 77.7286, 61.1841, 25.5077,\n",
       "        46.8260, 48.0008])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(tl.norm(out_als.factors[0], 2, axis = 0))\n",
    "    \n",
    "out_als.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS + post quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46.5547, 22.5584, 18.8045, 74.0972, 23.3725, 78.3342, 61.5168, 25.4934,\n",
      "        46.8735, 48.2320])\n",
      "||tensor - als_factors_quantized||: 1.0523691177368164\n"
     ]
    }
   ],
   "source": [
    "qfactors_post = []\n",
    "scales_post = []\n",
    "zero_points_post = []\n",
    "\n",
    "weights_post = copy.deepcopy(out_als.weights)\n",
    "\n",
    "for i in range(len(out_als.factors)):\n",
    "    q, s, z = quantize_qint(out_als.factors[i], **params_qint, return_scale_zeropoint = True)\n",
    "    qfactors_post.append(q)\n",
    "    scales_post.append(s)\n",
    "    zero_points_post.append(z)\n",
    "    \n",
    "    weights_post /=  tl.norm(q, order = 2, axis = 0)\n",
    "    \n",
    "print(weights_post)\n",
    "\n",
    "\n",
    "qt_post = kruskal_to_tensor(KruskalTensor((weights_post, qfactors_post)))\n",
    "rec_error_qpost = tl.norm(t - qt_post)\n",
    "\n",
    "print('||tensor - als_factors_quantized||: {}'.format(rec_error_qpost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([ -5,  -2,  46,  10, -46,  63,   8,  38, -50, -24], dtype=torch.int32),\n",
       "  tensor([-23, -33,  57,  15,  -1, -28, -32, -26,  -6,  -2], dtype=torch.int32),\n",
       "  tensor([ -40,   -2,   24,  -37,   10,  -38,  -13,   36, -127,   61],\n",
       "         dtype=torch.int32)],\n",
       " [tensor([0.0032, 0.0030, 0.0031, 0.0035, 0.0031, 0.0037, 0.0035, 0.0029, 0.0036,\n",
       "          0.0031]),\n",
       "  tensor([0.0031, 0.0037, 0.0043, 0.0029, 0.0037, 0.0040, 0.0038, 0.0036, 0.0039,\n",
       "          0.0039]),\n",
       "  tensor([0.0036, 0.0044, 0.0046, 0.0036, 0.0043, 0.0039, 0.0036, 0.0036, 0.0025,\n",
       "          0.0038])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_points_post, scales_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||tensor - fals_factors||: 21.62333106994629\n",
      "||tensor - qals_factors||: 21.653894424438477\n"
     ]
    }
   ],
   "source": [
    "(fout, qout), (errors, qerrors), scales, zero_points = quantized_parafac(t, rank,\\\n",
    "                                                                         init=init,\\\n",
    "                                                                         random_state=random_state,\\\n",
    "                                                                         **params_als_shared,\\\n",
    "                                                                         **params_qals,\\\n",
    "                                                                         **params_qint)\n",
    "\n",
    "t_approx_qals = kruskal_to_tensor(KruskalTensor(qout))\n",
    "rec_error_qals = tl.norm(t - t_approx_qals)\n",
    "\n",
    "t_approx_fals = kruskal_to_tensor(KruskalTensor(fout))\n",
    "rec_error_fals = tl.norm(t - t_approx_fals)\n",
    "\n",
    "print('||tensor - fals_factors||: {}'.format(rec_error_fals))\n",
    "print('||tensor - qals_factors||: {}'.format(rec_error_qals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "tensor([1.0010, 1.0003, 0.9985, 0.9990, 0.9993, 0.9984, 0.9995, 0.9997, 1.0002,\n",
      "        1.0005])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "tensor([1.0010, 1.0003, 0.9985, 0.9990, 0.9993, 0.9984, 0.9995, 0.9997, 1.0002,\n",
      "        1.0005])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "tensor([1.0010, 1.0003, 0.9985, 0.9990, 0.9993, 0.9984, 0.9995, 0.9997, 1.0002,\n",
      "        1.0005])\n",
      "tensor([68.9587, 46.9449, 45.4421, 18.2753, 74.2930, 70.0987, 25.3675, 79.4484,\n",
      "        22.5150, 48.1033])\n",
      "tensor([68.7769, 46.9411, 45.3775, 18.2146, 74.1132, 70.1068, 25.3691, 79.1590,\n",
      "        22.4923, 47.9603])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(tl.norm(fout.factors[0], 2, axis = 0))\n",
    "    print(tl.norm(qout.factors[0], 2, axis = 0))\n",
    "    \n",
    "    \n",
    "print(qout.weights)\n",
    "print(fout.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_factors(factors_flatten, shapes):\n",
    "    factors_restored = []\n",
    "    l = 0\n",
    "    for shape in shapes:\n",
    "        dl = np.prod(shape)\n",
    "        factors_restored.append(torch.tensor(factors_flatten)[l : l + dl].reshape(shape))\n",
    "        l += dl\n",
    "    return factors_restored\n",
    "\n",
    "\n",
    "def norm_error(factors_flatten, shapes, t, weights = None,\\\n",
    "               scales = None, zero_points = None):\n",
    "    \n",
    "    factors_restored = restore_factors(factors_flatten, shapes)\n",
    "    if scales is not None:\n",
    "        factors_restored = [(factors_restored[i] - zero_points[i]) * scales[i]\\\n",
    "                            for i in range(len(scales))]\n",
    "\n",
    "    tensor_restored = kruskal_to_tensor(KruskalTensor((weights, factors_restored)))\n",
    "\n",
    "    norm_error = tl.norm(tensor_restored - t)\n",
    "  \n",
    "    global i\n",
    "    global gnorm\n",
    "    i += 1\n",
    "    gnorm = float(norm_error)\n",
    "    \n",
    "    return float(norm_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS + post quantization + simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   8.0000,  -74.0000,   48.0000,  -31.0000,  -55.0000,   80.0000,\n",
       "         -128.0000,   86.0000,  -39.0000,  -51.0000],\n",
       "        [-115.0000,  -96.0000,   -9.0000,   34.0000,  113.0000,   85.0000,\n",
       "          -35.0000,  -99.0000,  -15.0000,   -9.0000],\n",
       "        [ -15.0000,   63.0000,  -55.0000,  101.0000, -125.0000,   92.0000,\n",
       "            1.0000,  -99.0000,  -30.0000,  -55.0000],\n",
       "        [  50.0000, -125.0000,   75.0000,  -67.0000,  -10.0000,   44.0000,\n",
       "          -93.0000,   55.0000,  126.0000,   -1.0000],\n",
       "        [  52.0000,   13.0000,   23.0000,   -8.0000,   42.0000, -128.0000,\n",
       "          -61.0000,  109.0000,  -17.0000,  119.0000],\n",
       "        [  92.0000,  123.0000, -111.0000,  -88.0000,  -52.0000,   21.0000,\n",
       "           28.0000,   77.0000,    2.0000,   75.0000],\n",
       "        [ -38.0000,   73.0000,  127.0000,  126.0000,  -70.0000,  -84.0000,\n",
       "           60.0000,   25.0000,  -41.0000,  -95.0000],\n",
       "        [ -14.0000,  -82.0000,   83.0000, -128.0000, -128.0000,  126.0000,\n",
       "           43.0000,   53.0000,   51.0000, -128.0000],\n",
       "        [ 127.0000,  -96.0000,  -48.0000,   67.0000,  -11.0000,   58.0000,\n",
       "          -34.0000,   42.0000,  -37.0000,   79.0000],\n",
       "        [-114.0000,   29.0000,  -38.0000,  -41.0000, -112.0000,   67.0000,\n",
       "           99.0000, -128.0000, -128.0000,  -10.0000],\n",
       "        [  -1.0000,   85.0000, -128.0000,  -15.0000,   -3.0000,   85.0000,\n",
       "           24.0000,    7.0000,   16.0000, -105.0000],\n",
       "        [ -84.0000,    9.0000,  -24.0000,  -30.0000,  126.0000,  120.0000,\n",
       "          -53.0000,  127.0000,  -84.0000,  126.0000],\n",
       "        [-123.0000,  -16.0000,   61.0000,   11.0000,   21.0000,   42.0000,\n",
       "          126.0000, -103.0000,  -84.0000,  -52.0000],\n",
       "        [ -23.0000, -128.0000,  -17.0000,  -31.0000,   55.0000,  120.0000,\n",
       "            6.0000,  -60.0000,   48.0000,   90.0000],\n",
       "        [ -29.0000,  126.0000,  110.0000,   77.0000,  -51.0000,   58.0000,\n",
       "           67.0000,   90.0000,  -84.0000,  -11.0000],\n",
       "        [-128.0000,  -12.0000,   61.0000,  -70.0000, -108.0000,   99.0000,\n",
       "          104.0000,   28.0000,   31.0000,    3.0000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmin=-128\n",
    "qmax=127\n",
    "qfactors_post[0]/scales_post[0] + zero_points_post[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qmin = -128\n",
    "# qmax = 127\n",
    "qfactors_post_int = [qfactors_post[i]/scales_post[i] + zero_points_post[i] \\\n",
    "                     for i in range(len(qfactors_post))]\n",
    "\n",
    "shapes = [factor.shape for factor in qfactors_post_int]\n",
    "factors_flatten_init =  torch.cat([factor.flatten() for factor in qfactors_post_int])\n",
    "factors_flatten_init = factors_flatten_init.type(torch.int8)\n",
    "\n",
    "\n",
    "bsa_als = None\n",
    "\n",
    "# numpy_to_struct = {np.float32 : 'f', np.float64 : 'd',  np.float16 : 'e',\\\n",
    "#                    np.int8 : 'b', np.int16 : 'h', np.int32 : 'i', np.int64 : 'q',\\\n",
    "#                    np.uint8 : 'B', np.uint16 : 'H', np.uint32 : 'I', np.uint64 : 'Q'}\n",
    "\n",
    "\n",
    "mask = np.zeros(8).astype(bool)\n",
    "mask[:] = True\n",
    "\n",
    "neighbor_params = {'nb':1, 'mask': mask}\n",
    "neighbor = p.sa.MaskedBitsNeighbor(**neighbor_params)\n",
    "\n",
    "i = 0\n",
    "gnorm = 0\n",
    "bsa_als = p.BinarySA(partial(norm_error,\n",
    "                             shapes = shapes, t = t, weights = weights_post,\\\n",
    "                             scales = scales_post, zero_points = zero_points_post),\\\n",
    "                     np.array(factors_flatten_init).astype(np.int8),\\\n",
    "                     [(-2**7, 2**7)]*len(factors_flatten_init),\\\n",
    "                     'i'*len(factors_flatten_init),\\\n",
    "                     emax = 1e-10,\\\n",
    "                     imax = 10000,\\\n",
    "                     T0 = 1,\\\n",
    "                     rt = 0.8, neighbor = neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0, i = 273, norm_error = 1.1724416017532349\n",
      "round 100, i = 1190, norm_error = 1.0019264221191406\n",
      "round 200, i = 1896, norm_error = 0.9990823864936829\n",
      "round 300, i = 358, norm_error = 0.9930474162101746\n",
      "round 400, i = 848, norm_error = 0.9800000786781311\n",
      "round 500, i = 388, norm_error = 0.9783644080162048\n"
     ]
    }
   ],
   "source": [
    "# make sense to run several times\n",
    "for r in range(10000):\n",
    "    flatten_factors_opt_als, error_als =  bsa_als()\n",
    "    if r % 100 == 0:\n",
    "        print('round {}, i = {}, norm_error = {}'.format(r, i, gnorm))\n",
    "    i = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 49.30796813964844, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 56.129146575927734, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 128.5807342529297, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 19.572996139526367, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 86.55799865722656, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 88.92695617675781, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 118.18357849121094, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 19.79806900024414, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 28.945478439331055, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 88.05354309082031, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 24.97346305847168, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 132.3879852294922, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 34.07567596435547, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 56.455169677734375, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 137.1123046875, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 25.900699615478516, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 31.178842544555664, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 47.55691146850586, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 116.30805969238281, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 127.49342346191406, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 51.50337600708008, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 2.9002296924591064, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 111.77404022216797, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 17.919031143188477, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 113.45081329345703, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 10.63309383392334, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 64.27774047851562, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 1.5173324346542358, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 94.03413391113281, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 88.94832611083984, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 116.33380126953125, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 67.77375030517578, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 116.79926300048828, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 35.2265625, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 101.44928741455078, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 27.047550201416016, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 86.4917984008789, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 48.797061920166016, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 41.1579475402832, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 130.63229370117188, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 87.73275756835938, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 86.91362762451172, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 40.226890563964844, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 28.011837005615234, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 42.89811325073242, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 123.46251678466797, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 86.0302963256836, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 1.6412869691848755, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 131.12893676757812, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 7.948733806610107, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 4.119872093200684, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 119.05669403076172, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 53.71949005126953, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 4.764957904815674, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 24.993610382080078, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 113.44274139404297, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 126.09327697753906, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n",
      "Norm error: 0.6827762126922607, type : torch.float32\n"
     ]
    }
   ],
   "source": [
    "flatten_factors_opt_als, error_als =  bsa_als()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QALS + simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  88.0000, -127.0000],\n",
       "         [  30.0000,   49.0000],\n",
       "         [  32.0000,  -75.0000],\n",
       "         [  -4.0000, -127.0000],\n",
       "         [ 109.0000,   10.0000]]),\n",
       " (tensor([0.0068, 0.0048]),\n",
       "  tensor([0.0060, 0.0046]),\n",
       "  tensor([0.0048, 0.0069])),\n",
       " (tensor([-1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1], dtype=torch.int32),\n",
       "  tensor([-1, -1], dtype=torch.int32)),\n",
       " tensor([113.6810,  46.5381]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qout.factors[0]/scales[0], scales, zero_points, qout.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 0.8272514343261719, type : torch.float32\n"
     ]
    }
   ],
   "source": [
    "qout_factors_int = [qout.factors[i]/scales[i]+zero_points[i] for i in range(len(qout.factors))]\n",
    "\n",
    "shapes = [factor.shape for factor in qout_factors_int]\n",
    "factors_flatten_init =  torch.cat([factor.flatten() for factor in qout_factors_int])\n",
    "factors_flatten_init = factors_flatten_init.type(torch.int8)\n",
    "\n",
    "\n",
    "bsa_qals = None\n",
    "\n",
    "# numpy_to_struct = {np.float32 : 'f', np.float64 : 'd',  np.float16 : 'e',\\\n",
    "#                    np.int8 : 'b', np.int16 : 'h', np.int32 : 'i', np.int64 : 'q',\\\n",
    "#                    np.uint8 : 'B', np.uint16 : 'H', np.uint32 : 'I', np.uint64 : 'Q'}\n",
    "\n",
    "\n",
    "mask = np.zeros(8).astype(bool)\n",
    "mask[-2:] = True\n",
    "\n",
    "neighbor_params = {'nb':2, 'mask': mask}\n",
    "neighbor = p.sa.MaskedBitsNeighbor(**neighbor_params)\n",
    "\n",
    "bsa_qals = p.BinarySA(partial(norm_error,\\\n",
    "                         shapes = shapes, t = t, weights = qout.weights,\\\n",
    "                         scales = scales, zero_points = zero_points),\\\n",
    "                 np.array(factors_flatten_init).astype(np.int8),\\\n",
    "#                  np.array(flatten_factors_opt),\\\n",
    "                 [(-2**7, 2**7)]*len(factors_flatten_init),\\\n",
    "                 'i'*len(factors_flatten_init),\\\n",
    "                  emax = 1e-10,\\\n",
    "                  imax = 10000,\\\n",
    "                  T0 = 1,\\\n",
    "                  rt = 0.8, neighbor = neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sense to run several times\n",
    "for j in range(100):\n",
    "    print('=========================={}=========================='.format(j))\n",
    "    flatten_factors_opt_qals, error_qals =  bsa_qals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 0.9785531759262085, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 26.667634963989258, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 83.25546264648438, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 23.067344665527344, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 140.20301818847656, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 113.11274719238281, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 93.16915130615234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 92.21993255615234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.027391791343689, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 71.94252014160156, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 68.17047119140625, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 53.569068908691406, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 123.57684326171875, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 98.60803985595703, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 70.00127410888672, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.9930390119552612, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 56.52869415283203, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 69.87275695800781, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 24.00259017944336, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 90.6910400390625, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 20.208038330078125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 179.85134887695312, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 87.71478271484375, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 50.715023040771484, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 25.076292037963867, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 104.7175064086914, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 81.62915802001953, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 34.48845672607422, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 103.16514587402344, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 29.631698608398438, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 111.47021484375, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 8.634587287902832, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 65.284423828125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 114.51115417480469, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 141.55386352539062, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 76.07452392578125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 111.99761962890625, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 58.9542236328125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 115.52494812011719, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 54.07899475097656, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 77.93197631835938, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 100.97486114501953, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 68.43563079833984, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 116.23857879638672, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.5778732299804688, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 63.67668914794922, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 31.942564010620117, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 123.01424407958984, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 53.31269073486328, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.1710493564605713, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 86.49686431884766, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 8.101276397705078, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 80.88773345947266, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 44.0850715637207, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 50.1147575378418, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 87.20040130615234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 40.705745697021484, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 20.033884048461914, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 38.47406768798828, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 78.04489135742188, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 67.50006866455078, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 13.306150436401367, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 86.73918151855469, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 57.44251251220703, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 102.068359375, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 6.415162563323975, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 133.00733947753906, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 71.9441146850586, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.7850099802017212, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 84.64088439941406, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 18.72393226623535, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 70.91810607910156, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 89.65914154052734, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 28.043174743652344, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 27.490114212036133, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 122.56171417236328, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 68.91058349609375, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 85.85923767089844, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 27.792293548583984, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 55.53066635131836, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 101.23522186279297, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 116.29711151123047, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 44.163734436035156, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 51.38204574584961, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 78.45218658447266, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 23.795808792114258, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 115.31282806396484, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 135.5431671142578, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 106.729248046875, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 110.54463958740234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 45.5439338684082, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 11.822174072265625, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 72.16120910644531, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 25.369916915893555, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 46.07764434814453, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 110.01531982421875, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 39.69013977050781, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 98.70817565917969, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 78.1717529296875, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 34.37144088745117, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 40.90012741088867, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 78.74363708496094, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 40.85390090942383, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 20.552064895629883, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 4.052990436553955, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 72.93712615966797, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 18.819454193115234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 123.15255737304688, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 123.75333404541016, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 3.712662696838379, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 85.65702056884766, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 50.06870651245117, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 47.84836196899414, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 62.54499816894531, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 112.07149505615234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 33.432369232177734, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 12.57543659210205, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 124.57184600830078, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 27.15338706970215, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.0392043590545654, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 63.734352111816406, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 96.57501220703125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 31.21882438659668, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 116.48101043701172, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 30.667043685913086, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 63.81818389892578, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 55.341453552246094, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 53.86306381225586, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 35.82501220703125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 36.491973876953125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 29.041677474975586, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 92.93517303466797, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 119.13105010986328, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm error: 129.10337829589844, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 115.65867614746094, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 69.82952880859375, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.0807952880859375, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 88.44097137451172, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 54.795433044433594, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 72.8763656616211, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 86.60588073730469, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 70.5448226928711, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 76.43610382080078, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 98.67208862304688, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 157.97117614746094, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 35.17778396606445, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 123.05078125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 72.3744888305664, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 117.65076446533203, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 47.53634262084961, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.396328330039978, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 56.34572219848633, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 101.22193145751953, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 24.290054321289062, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 90.53145599365234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 108.79940795898438, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 134.88897705078125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 118.97208404541016, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 59.95082473754883, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 38.85879135131836, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 68.51567077636719, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 106.53987884521484, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 77.02871704101562, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 52.353416442871094, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 127.82188415527344, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 50.50417709350586, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 16.81122589111328, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 107.05692291259766, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 8.084253311157227, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 148.19175720214844, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 1.91680908203125, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 90.15120697021484, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 89.20600128173828, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 35.62441635131836, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 104.20567321777344, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 120.44283294677734, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 85.27486419677734, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 101.10845184326172, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 8.484980583190918, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 47.269775390625, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 9.70561408996582, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 39.68867874145508, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 26.261308670043945, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 34.04547119140625, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 62.21440505981445, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 57.368831634521484, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 69.59247589111328, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 95.48046875, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 42.11497497558594, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 64.67515563964844, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 10.966943740844727, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 109.86238098144531, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 61.91801452636719, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 3.151207447052002, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 25.131284713745117, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 158.47457885742188, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 54.14225387573242, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 84.45918273925781, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 51.291690826416016, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 101.76597595214844, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 132.1437225341797, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 117.64376068115234, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 66.7418212890625, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 12.933099746704102, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 29.22010040283203, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 139.5994415283203, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 10.303430557250977, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 109.59522247314453, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 76.41912841796875, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 85.49927520751953, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 65.7827377319336, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 74.04810333251953, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 118.50607299804688, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 92.14964294433594, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 26.86408042907715, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n",
      "Norm error: 0.5835343599319458, type : torch.float32\n"
     ]
    }
   ],
   "source": [
    "flatten_factors_opt_qals, error_qals =  bsa_qals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-20,\n",
       " 59,\n",
       " -46,\n",
       " 71,\n",
       " -44,\n",
       " -46,\n",
       " 76,\n",
       " -38,\n",
       " 14,\n",
       " 48,\n",
       " -11,\n",
       " -36,\n",
       " 8,\n",
       " 55,\n",
       " 54,\n",
       " -60,\n",
       " -14,\n",
       " 4,\n",
       " -10,\n",
       " -6,\n",
       " -20,\n",
       " 18,\n",
       " -16,\n",
       " -31,\n",
       " -3,\n",
       " -54,\n",
       " 24,\n",
       " -4,\n",
       " 46,\n",
       " 14,\n",
       " 22,\n",
       " -15,\n",
       " -66,\n",
       " -8,\n",
       " 34,\n",
       " 20,\n",
       " -3,\n",
       " -32,\n",
       " 36,\n",
       " 29,\n",
       " 76,\n",
       " 40,\n",
       " -60,\n",
       " -44,\n",
       " 9,\n",
       " 38,\n",
       " -83,\n",
       " -7,\n",
       " -6,\n",
       " 4,\n",
       " 8,\n",
       " -49,\n",
       " -53,\n",
       " 57,\n",
       " 8,\n",
       " -32,\n",
       " -56,\n",
       " 33,\n",
       " -18,\n",
       " -4,\n",
       " 92,\n",
       " 0,\n",
       " -44,\n",
       " 0,\n",
       " 68,\n",
       " -3,\n",
       " 24,\n",
       " 53,\n",
       " 63,\n",
       " -48,\n",
       " -80,\n",
       " -4,\n",
       " 20,\n",
       " 0,\n",
       " -23,\n",
       " -8,\n",
       " 27,\n",
       " 2,\n",
       " -29,\n",
       " 4,\n",
       " 4,\n",
       " 87,\n",
       " -26,\n",
       " 0,\n",
       " 53,\n",
       " -28,\n",
       " -28,\n",
       " 56,\n",
       " -36,\n",
       " 12,\n",
       " -44,\n",
       " -44,\n",
       " -15,\n",
       " 34,\n",
       " -26,\n",
       " 3,\n",
       " -34,\n",
       " 55,\n",
       " 90,\n",
       " 7,\n",
       " -35,\n",
       " 12,\n",
       " -17,\n",
       " -41,\n",
       " 60,\n",
       " 65,\n",
       " 77,\n",
       " -69,\n",
       " 4,\n",
       " 12,\n",
       " -12,\n",
       " 101,\n",
       " -52,\n",
       " -42,\n",
       " -25,\n",
       " -117,\n",
       " -61,\n",
       " 97,\n",
       " 47,\n",
       " 9,\n",
       " -66,\n",
       " -3,\n",
       " -16,\n",
       " -24,\n",
       " 35,\n",
       " 23,\n",
       " -23,\n",
       " -6,\n",
       " -3,\n",
       " 2,\n",
       " -12,\n",
       " -52,\n",
       " 52,\n",
       " -16,\n",
       " 32,\n",
       " 56,\n",
       " -28,\n",
       " -33,\n",
       " 25,\n",
       " -36,\n",
       " 31,\n",
       " 11,\n",
       " -6,\n",
       " 55,\n",
       " 50,\n",
       " 51,\n",
       " 36,\n",
       " -37,\n",
       " 15,\n",
       " -77,\n",
       " -8,\n",
       " -18,\n",
       " -41,\n",
       " -112,\n",
       " 1,\n",
       " 14,\n",
       " -53,\n",
       " -38,\n",
       " -71,\n",
       " -55,\n",
       " -35,\n",
       " -64,\n",
       " -40,\n",
       " -50,\n",
       " -19,\n",
       " -44,\n",
       " 47,\n",
       " 28,\n",
       " -12,\n",
       " 36,\n",
       " -71,\n",
       " 28,\n",
       " 103,\n",
       " -15,\n",
       " 8,\n",
       " -41,\n",
       " 33,\n",
       " 1,\n",
       " 26,\n",
       " -64,\n",
       " -56,\n",
       " 21,\n",
       " 58,\n",
       " 91,\n",
       " -15,\n",
       " 16,\n",
       " 52,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " -54,\n",
       " -12,\n",
       " -32,\n",
       " 22,\n",
       " -28,\n",
       " 93,\n",
       " -16,\n",
       " 92,\n",
       " -57,\n",
       " -51,\n",
       " -85,\n",
       " -18,\n",
       " 0,\n",
       " 40,\n",
       " 54,\n",
       " 53,\n",
       " -47,\n",
       " -12,\n",
       " -42,\n",
       " -28,\n",
       " 17,\n",
       " -52,\n",
       " -57,\n",
       " -40,\n",
       " 29,\n",
       " 27,\n",
       " -111,\n",
       " 25,\n",
       " 60,\n",
       " 7,\n",
       " -100,\n",
       " -12,\n",
       " -23,\n",
       " -28,\n",
       " -1,\n",
       " -31,\n",
       " 60,\n",
       " -21,\n",
       " 41,\n",
       " 40,\n",
       " -28,\n",
       " 45,\n",
       " 37,\n",
       " 74,\n",
       " -23,\n",
       " -21,\n",
       " -60,\n",
       " -17,\n",
       " 76,\n",
       " 4,\n",
       " -97,\n",
       " -39,\n",
       " -128,\n",
       " -9,\n",
       " -126,\n",
       " 25,\n",
       " 65,\n",
       " 21,\n",
       " -17,\n",
       " 14,\n",
       " 8,\n",
       " -13,\n",
       " -66,\n",
       " -21,\n",
       " 23,\n",
       " -4,\n",
       " -2,\n",
       " -34,\n",
       " -62,\n",
       " -72,\n",
       " -19,\n",
       " 62,\n",
       " 62,\n",
       " 46,\n",
       " 14,\n",
       " -64,\n",
       " 0,\n",
       " -39,\n",
       " -128,\n",
       " 40,\n",
       " 55,\n",
       " 11,\n",
       " 85,\n",
       " 64,\n",
       " -10,\n",
       " -7,\n",
       " -15,\n",
       " 45,\n",
       " -80,\n",
       " -58,\n",
       " -42,\n",
       " -48,\n",
       " -56,\n",
       " -1,\n",
       " 38,\n",
       " -3,\n",
       " -49,\n",
       " -4,\n",
       " -36,\n",
       " 74,\n",
       " 40,\n",
       " -101,\n",
       " 14,\n",
       " 81,\n",
       " 82,\n",
       " 72,\n",
       " -95,\n",
       " 40,\n",
       " -43,\n",
       " 0,\n",
       " 8,\n",
       " -36,\n",
       " -55,\n",
       " 55,\n",
       " 78,\n",
       " -23,\n",
       " 100,\n",
       " 85,\n",
       " -16,\n",
       " -72,\n",
       " 48,\n",
       " -64,\n",
       " 64,\n",
       " 86,\n",
       " -34,\n",
       " 6,\n",
       " -9,\n",
       " 65,\n",
       " -26,\n",
       " -119,\n",
       " 0,\n",
       " -31,\n",
       " 48,\n",
       " 62,\n",
       " 5,\n",
       " -62,\n",
       " -22,\n",
       " -31)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_factors_opt_qals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2**7-1 + 2**7 ) == 2**8 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
